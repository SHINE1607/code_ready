{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image augmentation code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset. ... Image data augmentation is used to expand the training dataset in order to improve the performance and ability of the model to generalize. It is always have more data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image_paths, labels):\n",
    "    final_images  = []\n",
    "    \n",
    "    for i, path  in enumerate(image_paths):\n",
    "        img = imread(path)\n",
    "        img = img/255\n",
    "        img = resize(img, (256, 256))\n",
    "\n",
    "        final_images.append({\"image\": torch.tensor(img), \"target\": labels[i]})\n",
    "        rot = rotate(img, angle=45, mode = 'wrap')\n",
    "        flip1 = np.fliplr(img).copy()\n",
    "        flip2 = np.flipud(img).copy()\n",
    "        noise = random_noise(img,var=0.2**2)\n",
    "\n",
    "        final_images.append({\"image\": torch.tensor(rot), \"target\": labels[i]})\n",
    "        final_images.append({\"image\": torch.tensor(flip1), \"target\": labels[i]})\n",
    "        final_images.append({\"image\": torch.tensor(flip2), \"target\": labels[i]})\n",
    "        final_images.append({\"image\":torch.tensor(noise), \"target\": labels[i]})\n",
    "    \n",
    "    return final_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = ['./dataset/' + img_id for img_id in files]\n",
    "train_images = augmentation(image_paths, list(df_labels[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f for f in listdir(\"./dataset\") if isfile(join(\"./dataset\", f)) and f[-3:] == 'jpg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_labels = pd.DataFrame({\"image_id\": [], \"label\": []})\n",
    "for file  in files:\n",
    "    if 'sunrise' in file:\n",
    "        label = int(1)\n",
    "    elif 'rain' in file:\n",
    "        label = int(2)\n",
    "    elif 'cloudy' in file:\n",
    "        label = int(3)\n",
    "    elif 'shine' in file:\n",
    "        label = int(4)\n",
    "    else:\n",
    "        label = int(5)\n",
    "    df_labels.loc[len(df_labels)] = [file, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunrise192.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunrise186.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy274.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloudy260.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunrise151.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  sunrise192.jpg    1.0\n",
       "1  sunrise186.jpg    1.0\n",
       "2   cloudy274.jpg    3.0\n",
       "3   cloudy260.jpg    3.0\n",
       "4  sunrise151.jpg    1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python37764bitmyenvconda823dfb8e79a54b2babc4116ecd4d023d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
